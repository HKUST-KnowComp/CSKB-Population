{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from random import sample\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "sys.path.append('../')\n",
    "from utils.aser_to_glucose import generate_aser_to_glucose_dict\n",
    "from utils.glucose_utils import glucose_subject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the filtered ASER graph\n",
    "aser = nx.read_gpickle('../../data/ASER_data//G_aser_core.pickle')\n",
    "node2id_dict = np.load(\"../../dataset/ASER_core_node2id.npy\", allow_pickle=True).item()\n",
    "id2node_dict = dict([(node2id_dict[node], node) for node in node2id_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Statistics in ASER_Norm:\n",
      "\n",
      "In list 1, Total Head: 55388\tMatched Head: 32439 (58.599999999999994%)\tMatched Tail: 28957 (52.300000000000004%)\tMatched Both: 18135 (32.7%)\n",
      "In list 2, Total Head: 37127\tMatched Head: 26271 (70.8%)\tMatched Tail: 19019 (51.2%)\tMatched Both: 14582 (39.300000000000004%)\n",
      "In list 3, Total Head: 30456\tMatched Head: 18534 (60.9%)\tMatched Tail: 15615 (51.300000000000004%)\tMatched Both: 9361 (30.7%)\n",
      "In list 4, Total Head: 29269\tMatched Head: 25547 (87.3%)\tMatched Tail: 15445 (52.800000000000004%)\tMatched Both: 13846 (47.3%)\n",
      "In list 5, Total Head: 22011\tMatched Head: 16544 (75.2%)\tMatched Tail: 11867 (53.900000000000006%)\tMatched Both: 9312 (42.3%)\n",
      "In list 6, Total Head: 50312\tMatched Head: 26641 (53.0%)\tMatched Tail: 27359 (54.400000000000006%)\tMatched Both: 15525 (30.9%)\n",
      "In list 7, Total Head: 36613\tMatched Head: 20034 (54.7%)\tMatched Tail: 31474 (86.0%)\tMatched Both: 17389 (47.5%)\n",
      "In list 8, Total Head: 16183\tMatched Head: 8372 (51.7%)\tMatched Tail: 8628 (53.300000000000004%)\tMatched Both: 4549 (28.1%)\n",
      "In list 9, Total Head: 12855\tMatched Head: 7723 (60.099999999999994%)\tMatched Tail: 10663 (82.89999999999999%)\tMatched Both: 6810 (53.0%)\n",
      "In list 10, Total Head: 13885\tMatched Head: 7578 (54.6%)\tMatched Tail: 9393 (67.60000000000001%)\tMatched Both: 5407 (38.9%)\n",
      "\n",
      "\n",
      "In total: Total Head: 304099\tMatched Head: 189683 (62.4%)\tMatched Tail: 178420 (58.699999999999996%)\tMatched Both: 114916 (37.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# We test the coverage in the norm ASER\n",
    "print_str = \"\\n\\nStatistics in ASER_Norm:\\n\\n\"\n",
    "total_count, total_head, total_tail, total_both = 0, 0, 0, 0\n",
    "for i in trange(1, 11):\n",
    "    list_count, list_head, list_tail, list_both = len(glucose_matching[i]), 0, 0, 0\n",
    "    for ind in range(len(glucose_matching[i])):\n",
    "        for h in glucose_matching[i][ind]['total_head']:\n",
    "            if h in node2id_dict.keys():\n",
    "                list_head += 1\n",
    "                break\n",
    "        for t in glucose_matching[i][ind]['total_tail']:\n",
    "            if t in node2id_dict.keys():\n",
    "                list_tail += 1\n",
    "                break\n",
    "        for h, t in glucose_matching[i][ind]['both']:\n",
    "            if h in node2id_dict.keys() and t in node2id_dict.keys():\n",
    "                list_both += 1\n",
    "                break\n",
    "    print_str += (\n",
    "        \"In list {}, Total Head: {}\\tMatched Head: {} ({}%)\\tMatched Tail: {} ({}%)\\tMatched Both: {} ({}%)\\n\"\n",
    "            .format(i, list_count, list_head, round(list_head / list_count, 3) * 100,\n",
    "                    list_tail, round(list_tail / list_count, 3) * 100, list_both,\n",
    "                    round(list_both / list_count, 3) * 100))\n",
    "    total_count += list_count\n",
    "    total_head += list_head\n",
    "    total_tail += list_tail\n",
    "    total_both += list_both\n",
    "print_str += (\n",
    "    \"\\n\\nIn total: Total Head: {}\\tMatched Head: {} ({}%)\\tMatched Tail: {} ({}%)\\tMatched Both: {} ({}%)\".format(\n",
    "        total_count, total_head, 100 * round(total_head / total_count, 3),\n",
    "        total_tail, 100 * round(total_tail / total_count, 3), total_both, 100 * round(total_both / total_count, 3)))\n",
    "print(print_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge types in ASER:\n",
      "{'stative': 9307934, 'cause': 20596819, 'effect': 20596819}\n"
     ]
    }
   ],
   "source": [
    "# Do some ASER edge type statistics\n",
    "all_edge_types = {}\n",
    "for head, tail, feat_dict in aser.edges.data():\n",
    "    for r in feat_dict[\"edge_type\"]:\n",
    "        if r in all_edge_types.keys():\n",
    "            all_edge_types[r] += 1\n",
    "        else:\n",
    "            all_edge_types[r] = 1\n",
    "print(\"Edge types in ASER:\")\n",
    "print(all_edge_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_px_py(original: str):\n",
    "    return original.replace(\"PersonX\", \"[PX]\").replace(\"PersonY\", \"[PY]\").replace(\"[PX]\", \"PersonY\").replace(\n",
    "        \"[PY]\", \"PersonX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conceptualized_graph(G: nx.DiGraph):\n",
    "    G_conceptualized = nx.DiGraph()\n",
    "    for head, tail, feat_dict in tqdm(G.edges.data()):\n",
    "        head = id2node_dict[head]\n",
    "        tail = id2node_dict[tail]\n",
    "        head_split = head.split()\n",
    "        tail_split = tail.split()\n",
    "        head_subj = head_split[0]\n",
    "        tail_subj = tail_split[0]\n",
    "        relations = feat_dict[\"edge_type\"]\n",
    "        for r in relations:\n",
    "            if head_subj == tail_subj and head_subj in glucose_subject_list:\n",
    "                new_rel = r + \"_agent\"\n",
    "            elif head_subj != tail_subj and head_subj in glucose_subject_list and tail_subj in glucose_subject_list:\n",
    "                new_rel = r + \"_theme\"\n",
    "            else:\n",
    "                new_rel = r + \"_general\"\n",
    "            _, re_head, re_tail, _ = generate_aser_to_glucose_dict(head, tail, True)\n",
    "            re_head_reverse, re_tail_reverse = reverse_px_py(re_head), reverse_px_py(re_tail)\n",
    "            if len(re_head) > 0 and len(re_tail) > 0:\n",
    "                if G_conceptualized.has_edge(re_head, re_tail):\n",
    "                    G_conceptualized.add_edge(re_head, re_tail, relation=list(\n",
    "                        set(G_conceptualized[re_head][re_tail][\"relation\"] + [new_rel])))\n",
    "                else:\n",
    "                    G_conceptualized.add_edge(re_head, re_tail, relation=[new_rel])\n",
    "            if len(re_head_reverse) > 0 and len(re_tail_reverse) > 0:\n",
    "                if G_conceptualized.has_edge(re_head_reverse, re_tail_reverse):\n",
    "                    G_conceptualized.add_edge(re_head_reverse, re_tail_reverse, relation=list(\n",
    "                        set(G_conceptualized[re_head_reverse][re_tail_reverse][\"relation\"] + [new_rel])))\n",
    "                else:\n",
    "                    G_conceptualized.add_edge(re_head_reverse, re_tail_reverse, relation=[new_rel])\n",
    "    return G_conceptualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24764534/24764534 [23:01<00:00, 17922.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Conceptualization:\n",
      "Number of Edges: 24764534\tNumber of Nodes: 40339576\n",
      "\n",
      "After Conceptualization:\n",
      "Number of Edges: 41336290\tNumber of Nodes: 11872745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aser_conceptualized = get_conceptualized_graph(aser)\n",
    "print(\"Before Conceptualization:\\nNumber of Edges: {}\\tNumber of Nodes: {}\\n\".format(len(aser.edges), len(aser.nodes)))\n",
    "print(\"After Conceptualization:\\nNumber of Edges: {}\\tNumber of Nodes: {}\\n\".format(len(aser_conceptualized.edges),\n",
    "                                                                                    len(aser_conceptualized.nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gpickle(aser_conceptualized, '../../dataset/G_aser_concept.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the establishment be very clean', 'the food be amazingly fresh', {'relation': ['stative_general', 'effect_general', 'cause_general']})\n",
      "('PersonY hope so', 'PersonY be count on it', {'relation': ['cause_agent', 'effect_agent']})\n",
      "('PersonX want to talk to PersonY', 'PersonY go back to class', {'relation': ['effect_theme', 'cause_theme']})\n",
      "('it be a poor workplace culture', 'PersonX be comfortable', {'relation': ['stative_general', 'cause_general']})\n",
      "('PersonX be seat', 'the waitress sit PersonX', {'relation': ['effect_general', 'cause_general']})\n",
      "('the queen be drain the treasury of state', 'the king indulge pleasure to excess', {'relation': ['effect_general', 'cause_general']})\n",
      "('PeopleX will likely be permabann', 'PersonY upload a virus to site', {'relation': ['cause_general']})\n",
      "('the port close', 'there be a sharp snap', {'relation': ['effect_general', 'cause_general']})\n",
      "('PeopleX be fantastic', 'PersonX have be go there', {'relation': ['effect_general', 'cause_general']})\n",
      "('buddhist monastery be destroy', 'PeopleX number drop hundred to thirty-six', {'relation': ['effect_general', 'cause_general']})\n",
      "('PeopleX be smart', 'PeopleX look different', {'relation': ['stative_general', 'cause_general']})\n",
      "('some harm have come to PersonX', 'PersonY feel again', {'relation': ['effect_general', 'cause_general']})\n",
      "('PersonY can add PersonX', 'PersonY wan na play on pc', {'relation': ['effect_agent']})\n",
      "('it win t matter much', 'PersonY shall never fall in love', {'relation': ['effect_general', 'cause_general']})\n",
      "('there be no danger', 'PersonY have not be out the house for day', {'relation': ['stative_general', 'effect_general', 'cause_general']})\n",
      "('PersonY would pull', 'PersonX defend PersonZ', {'relation': ['effect_theme', 'cause_theme']})\n",
      "('PersonY reasoning be wrong', 'PersonY conclusion be wrong', {'relation': ['stative_agent', 'effect_agent']})\n",
      "('PersonY can pick up on cue', 'my fe be weak', {'relation': ['stative_general', 'effect_general', 'cause_general']})\n",
      "('PersonX go to york', 'maybe PersonY could have', {'relation': ['effect_general', 'cause_general']})\n",
      "('PeopleX take leave', 'the family shake hand with PeopleX', {'relation': ['effect_general', 'cause_general']})\n",
      "('be no reason', 'PersonX be a solo player', {'relation': ['stative_general', 'effect_general']})\n",
      "('PersonX be black', 'PersonX may pull', {'relation': ['cause_agent']})\n",
      "('PersonY will have a history', 'it will help', {'relation': ['effect_general', 'cause_general']})\n",
      "('it will pursue the subject satisfaction', 'it concentrate it', {'relation': ['effect_general', 'cause_general']})\n",
      "('PersonX should be replace', 'people start chant', {'relation': ['effect_general', 'cause_general']})\n",
      "('the sun beat down on head', 'PersonY sit on rock', {'relation': ['effect_general', 'cause_general']})\n",
      "('PersonY be ask a curious question by ii', 'a southern bishop visit the vatican ago', {'relation': ['effect_general', 'cause_general']})\n",
      "('PersonY be co', 'PersonY be write now', {'relation': ['cause_agent', 'effect_agent']})\n",
      "('d. gibbons make a six call', 'it turn out', {'relation': ['effect_general', 'cause_general']})\n",
      "('PeopleX have be consistent', 'the staff welcome', {'relation': ['effect_general', 'cause_general']})\n",
      "\n",
      "\n",
      "('PersonY would put combustion in setup', {})\n",
      "('PersonY have have at all', {})\n",
      "('PersonY be full in end', {})\n",
      "('people truly enjoy PeopleX job', {})\n",
      "('the manner of dress be a small thing', {})\n",
      "('PeopleX find out PersonX precise age', {})\n",
      "('the story have just begin', {})\n",
      "('it be pretty unremarkable', {})\n",
      "('PersonX take this notion of universe', {})\n",
      "('PersonX wait two hour in rain', {})\n"
     ]
    }
   ],
   "source": [
    "# Let's sample some ASER conceptualization to check whether it's correct\n",
    "for i in sample(list(aser_conceptualized.edges.data()), 30) + ['\\n'] + sample(list(aser_conceptualized.nodes.data()), 10):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's calculate the shortest path\n",
    "def get_shortest_path(G , head, tail):\n",
    "    try:\n",
    "        p = nx.shortest_path_length(G, source=head, target=tail)\n",
    "    except nx.NodeNotFound:\n",
    "        return -1\n",
    "    except nx.NetworkXNoPath:\n",
    "        return -1\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55388/55388 [01:30<00:00, 610.27it/s] \n",
      "100%|██████████| 37127/37127 [00:42<00:00, 873.48it/s] \n",
      "100%|██████████| 30456/30456 [02:23<00:00, 212.43it/s]\n",
      "100%|██████████| 29269/29269 [01:16<00:00, 381.58it/s]\n",
      "100%|██████████| 22011/22011 [00:38<00:00, 569.58it/s]\n",
      "100%|██████████| 50312/50312 [01:14<00:00, 674.72it/s] \n",
      "100%|██████████| 36613/36613 [01:11<00:00, 509.46it/s]\n",
      "100%|██████████| 16183/16183 [00:17<00:00, 939.47it/s] \n",
      "100%|██████████| 12855/12855 [00:36<00:00, 351.81it/s]\n",
      "100%|██████████| 13885/13885 [00:23<00:00, 598.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Shortest Path in Full ASER is: 2.717402138455962\n",
      "Average Shortest Path in Norm ASER is: 2.5518495605427085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "full_path, norm_path = [], []\n",
    "for i in range(1, 11):\n",
    "    for ind in trange(len(glucose_matching[i])):\n",
    "        norm_temp, full_temp = [], []\n",
    "        for h, t in glucose_matching[i][ind]['both']:\n",
    "            _, re_h, re_t, _ = generate_aser_to_glucose_dict(h, t, True)\n",
    "            if re_h in aser_conceptualized and re_t in aser_conceptualized:\n",
    "                norm_temp.append(get_shortest_path(aser_conceptualized, re_h, re_t))\n",
    "        if norm_temp:\n",
    "            try:\n",
    "                norm_path.append(min([i for i in norm_temp if i > 0]))\n",
    "            except ValueError:\n",
    "                norm_path.append(0)\n",
    "        else:\n",
    "            norm_path.append(0)\n",
    "        for h, t in glucose_matching[i][ind]['both']:\n",
    "            try:\n",
    "                hid = node2id_dict[h]\n",
    "                tid = node2id_dict[t]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            if hid in aser and tid in aser:\n",
    "                full_temp.append(get_shortest_path(aser, hid, tid))\n",
    "        if full_temp:\n",
    "            try:\n",
    "                full_path.append(min([i for i in full_temp if i > 0]))\n",
    "            except ValueError:\n",
    "                full_path.append(0)\n",
    "        else:\n",
    "            full_path.append(0)\n",
    "print(\"Average Shortest Path in Full ASER is: {}\".format(np.mean([i for i in full_path if i > 0])))\n",
    "print(\"Average Shortest Path in Norm ASER is: {}\".format(np.mean([i for i in norm_path if i > 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55388/55388 [01:26<00:00, 638.28it/s] \n",
      "100%|██████████| 37127/37127 [00:36<00:00, 1022.80it/s]\n",
      "100%|██████████| 30456/30456 [02:18<00:00, 219.31it/s]\n",
      "100%|██████████| 29269/29269 [01:10<00:00, 414.29it/s]\n",
      "100%|██████████| 22011/22011 [00:33<00:00, 648.41it/s] \n",
      "100%|██████████| 50312/50312 [01:09<00:00, 719.88it/s] \n",
      "100%|██████████| 36613/36613 [01:08<00:00, 533.21it/s]\n",
      "100%|██████████| 16183/16183 [00:14<00:00, 1112.10it/s]\n",
      "100%|██████████| 12855/12855 [00:32<00:00, 400.39it/s]\n",
      "100%|██████████| 13885/13885 [00:21<00:00, 644.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In No Direction Scenario:\n",
      "Average Shortest Path in Full ASER is: 2.7156457656474635\n",
      "Average Shortest Path in Norm ASER is: 2.5507897792026584\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average path in a simple graph:\n",
    "G_simple = nx.Graph()\n",
    "G_simple.add_nodes_from(aser_conceptualized)\n",
    "G_simple.add_edges_from(aser_conceptualized.edges.data())\n",
    "G_simple_full = nx.Graph()\n",
    "G_simple_full.add_nodes_from(aser)\n",
    "G_simple_full.add_edges_from(aser.edges.data())\n",
    "\n",
    "full_path, norm_path = [], []\n",
    "for i in range(1, 11):\n",
    "    for ind in trange(len(glucose_matching[i])):\n",
    "        norm_temp, full_temp = [], []\n",
    "        for h, t in glucose_matching[i][ind]['both']:\n",
    "            _, re_h, re_t, _ = generate_aser_to_glucose_dict(h, t, True)\n",
    "            if re_h in G_simple and re_t in G_simple:\n",
    "                norm_temp.append(get_shortest_path(G_simple, re_h, re_t))\n",
    "        if norm_temp:\n",
    "            try:\n",
    "                norm_path.append(min([i for i in norm_temp if i > 0]))\n",
    "            except ValueError:\n",
    "                norm_path.append(0)\n",
    "        else:\n",
    "            norm_path.append(0)\n",
    "        for h, t in glucose_matching[i][ind]['both']:\n",
    "            try:\n",
    "                hid = node2id_dict[h]\n",
    "                tid = node2id_dict[t]\n",
    "            except KeyError:\n",
    "                continue\n",
    "            if hid in G_simple_full and tid in G_simple_full:\n",
    "                full_temp.append(get_shortest_path(G_simple_full, hid, tid))\n",
    "        if full_temp:\n",
    "            try:\n",
    "                full_path.append(min([i for i in full_temp if i > 0]))\n",
    "            except ValueError:\n",
    "                full_path.append(0)\n",
    "        else:\n",
    "            full_path.append(0)\n",
    "print(\"In No Direction Scenario:\")\n",
    "print(\"Average Shortest Path in Full ASER is: {}\".format(np.mean([i for i in full_path if i > 0])))\n",
    "print(\"Average Shortest Path in Norm ASER is: {}\".format(np.mean([i for i in norm_path if i > 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Coverage for Glucose Graph is: 57.25%\n",
      "Edge Coverage for Glucose Graph is: 1.63%\n"
     ]
    }
   ],
   "source": [
    "# Now let's start merging with Glucose\n",
    "G_Glucose = nx.read_gpickle('../../dataset/G_Glucose.pickle')\n",
    "print(\"Node Coverage for Glucose Graph is: {}%\\nEdge Coverage for Glucose Graph is: {}%\".format(\n",
    "    100 * round(sum([node in aser_conceptualized for node in G_Glucose.nodes()]) / len(G_Glucose.nodes()), 4),\n",
    "    100 * round(sum([edge in aser_conceptualized.edges for edge in G_Glucose.edges()]) / len(G_Glucose.edges()), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Merging:\n",
      "Edges in ASER: 41336290\t\t\t\tNodes in ASER: 11872745\n",
      "\n",
      "\n",
      "After Merging:\n",
      "Edges in ASER+Glucose: 41568751\t\t\tNodes in ASER+Glucose: 11912389\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Merging:\\nEdges in ASER: {}\\t\\t\\t\\tNodes in ASER: {}\\n\".format(len(aser_conceptualized.edges()),\n",
    "                                                                       len(aser_conceptualized.nodes())))\n",
    "aser_conceptualized.add_nodes_from(list(G_Glucose.nodes.data()))\n",
    "aser_conceptualized.add_edges_from(list(G_Glucose.edges.data()))\n",
    "print(\"\\nAfter Merging:\\nEdges in ASER+Glucose: {}\\t\\t\\tNodes in ASER+Glucose: {}\".format(len(aser_conceptualized.edges()),\n",
    "                                                                                      len(aser_conceptualized.nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Edges: 232461\tNew Nodes: 39644\n"
     ]
    }
   ],
   "source": [
    "print(\"New Edges: {}\\tNew Nodes: {}\".format(len(aser_conceptualized.edges()) - 41336290,\n",
    "                                            len(aser_conceptualized.nodes()) - 11872745))\n",
    "nx.write_gpickle(aser_conceptualized, '../../dataset/G_aser_glucose.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
